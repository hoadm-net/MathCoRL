Metadata-Version: 2.4
Name: mint
Version: 0.1.0
Summary: Mathematical Intelligence Library for Function Prototype Prompting
Home-page: https://github.com/mathcorl/mint
Author: MathCoRL Team
Author-email: 
Project-URL: Bug Reports, https://github.com/mathcorl/mint/issues
Project-URL: Source, https://github.com/mathcorl/mint
Keywords: mathematics,ai,llm,function-prototype-prompting,mathematical-reasoning
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Mathematics
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: openai>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-openai>=0.1.0
Requires-Dist: langsmith>=0.1.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: pandas>=2.0.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: tqdm>=4.65.0
Requires-Dist: matplotlib>=3.7.0
Requires-Dist: seaborn>=0.12.0
Requires-Dist: jupyter>=1.0.0
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: project-url
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# Function Prototype Prompting (FPP) for Mathematical Problem Solving

A powerful system that uses Function Prototype Prompting to solve mathematical word problems by generating and executing Python code with predefined mathematical functions.

## 🚀 Overview

Function Prototype Prompting (FPP) is an innovative approach to mathematical problem solving that:

- **Provides structured function prototypes** to Large Language Models (LLMs)
- **Generates executable Python code** to solve mathematical problems
- **Uses predefined mathematical functions** for reliable computation
- **Supports multiple datasets** like SVAMP, GSM8K, FinQA, TabMWP, and TAT-QA
- **Integrates with LangChain** for advanced debugging and tracing

## ✨ Features

- 🔧 **25+ Predefined Mathematical Functions** - Basic arithmetic, statistics, comparisons, and more
- 🤖 **LangChain Integration** - Advanced LLM interaction with debugging support
- 📊 **Multiple Dataset Support** - Built-in support for popular math datasets
- 🔍 **LangSmith Tracing** - Optional debugging and performance monitoring
- 🎯 **High Accuracy** - Structured approach improves problem-solving reliability
- 🔒 **Safe Code Execution** - Controlled environment with predefined functions only
- 🎮 **Demo Mode** - Test without API keys using mock responses

## 📁 Project Structure

```
MathCoRL/
├── FPP.py                      # Main FPP implementation
├── demo_fpp.py                 # Demo script (no API key required)
├── setup.py                    # Interactive setup script
├── env.example                 # Environment configuration template
├── requirements.txt            # Dependencies
├── templates/
│   ├── function_prototypes.txt # Mathematical function definitions
│   └── fpp.txt                # FPP prompt template
├── mint/
│   ├── __init__.py
│   └── config.py              # Configuration management
└── datasets/
    ├── SVAMP/                 # SVAMP dataset
    ├── GSM8K/                 # GSM8K dataset  
    ├── FinQA/                 # FinQA dataset
    ├── TabMWP/                # TabMWP dataset
    └── TAT-QA/                # TAT-QA dataset
```

## 🛠️ Installation

### Prerequisites

- Python 3.8+
- OpenAI API key (for real testing)
- LangChain API key (optional, for LangSmith tracing)

### Quick Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd MathCoRL
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Run interactive setup**
```bash
python setup.py
```

### Manual Setup

1. **Install dependencies**
```bash
pip install -r requirements.txt
```

2. **Configure environment**
```bash
cp env.example .env
# Edit .env file with your API keys
```

## 🚀 Quick Start

### 1. Demo (No API Key Required)

Test the system with mock responses:

```bash
python demo_fpp.py
```

This will show you how FPP works with sample math problems and mock LLM responses.

### 2. Real API Testing

After setting up your OpenAI API key:

```bash
python FPP.py
```

### 3. Use in Your Code

```python
from FPP import FunctionPrototypePrompting
from mint.config import load_config

# Load configuration
config = load_config()

# Initialize FPP
fpp = FunctionPrototypePrompting(config)

# Solve a problem
question = "There are 15 apples. If you eat 3, how many are left?"
result = fpp.solve_problem(question)
print(f"Answer: {result}")
```

## ⚙️ Configuration

Create a `.env` file from the template:

```bash
cp env.example .env
```

### Required Settings
```env
OPENAI_API_KEY=your_openai_api_key_here
```

### Optional Settings
```env
# LangSmith (for debugging and tracing)
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=FPP-MathCoRL

# Model Settings
DEFAULT_MODEL=gpt-4
TEMPERATURE=0.0
MAX_TOKENS=1000

# Debug Settings
LOG_LEVEL=INFO
DEBUG_MODE=false
```

## 🧮 Mathematical Functions

FPP includes 25+ predefined mathematical functions:

### Basic Arithmetic
- `add(a, b)` - Addition
- `sub(a, b)` - Subtraction  
- `mul(a, b)` - Multiplication
- `div(a, b)` - Division
- `mod(a, b)` - Modulo
- `pow(a, b)` - Exponentiation

### Statistics
- `sum(numbers)` - Sum of list
- `mean(numbers)` - Average
- `median(numbers)` - Median value
- `mode(numbers)` - Most frequent value
- `count(numbers)` - Count elements

### Comparisons
- `greater_than(a, b)` - Check if a > b
- `less_than(a, b)` - Check if a < b
- `equal(a, b)` - Check if a == b

### Utilities
- `min(*args)` - Minimum value
- `max(*args)` - Maximum value
- `abs(a)` - Absolute value
- `round(a, digits)` - Round number
- `floor(a)` - Round down
- `ceil(a)` - Round up
- `percentage(part, whole)` - Calculate percentage
- `gcd(a, b)` - Greatest common divisor
- `lcm(a, b)` - Least common multiple

## 📊 Dataset Support

FPP supports multiple mathematical datasets:

### SVAMP Dataset
- **Type**: Elementary math word problems
- **Format**: JSON with ID, Body, Question, Answer, Type
- **Usage**: Primary testing dataset

### GSM8K Dataset  
- **Type**: Grade school math problems
- **Format**: JSONL with question and answer
- **Usage**: Advanced mathematical reasoning

### FinQA Dataset
- **Type**: Financial numerical reasoning
- **Format**: JSON with tables and questions
- **Usage**: Financial calculations

### TabMWP Dataset
- **Type**: Tabular math word problems
- **Format**: JSON with tables and questions  
- **Usage**: Table-based reasoning

### TAT-QA Dataset
- **Type**: Tabular and textual QA
- **Format**: JSON with tables and text
- **Usage**: Complex reasoning tasks

## 🔧 Usage Examples

### Solving Single Problem

```python
from FPP import FunctionPrototypePrompting
from mint.config import load_config

config = load_config()
fpp = FunctionPrototypePrompting(config)

# Simple arithmetic problem
question = "John has 25 marbles. He gives 7 to his friend. How many marbles does John have left?"
answer = fpp.solve_problem(question)
print(f"Answer: {answer}")
```

### Batch Processing

```python
# Process multiple problems
problems = [
    "There are 12 students. Each student has 3 books. How many books in total?",
    "A pizza is cut into 8 slices. If 3 slices are eaten, how many remain?",
    "Mary buys 4 packs of stickers. Each pack has 15 stickers. How many stickers total?"
]

for i, problem in enumerate(problems):
    result = fpp.solve_problem(problem)
    print(f"Problem {i+1}: {result}")
```

### Working with Datasets

```python
import json

# Load SVAMP dataset
with open('datasets/SVAMP/test.json', 'r') as f:
    svamp_data = json.load(f)

# Process first 5 problems
for problem in svamp_data[:5]:
    question = f"{problem['Body']} {problem['Question']}"
    predicted = fpp.solve_problem(question)
    actual = problem['Answer']
    
    print(f"Question: {question}")
    print(f"Predicted: {predicted}")
    print(f"Actual: {actual}")
    print(f"Correct: {'✓' if abs(predicted - actual) < 0.01 else '✗'}")
    print("-" * 50)
```

## 🐛 Troubleshooting

### Common Issues

1. **API Key Error**
   ```
   Error: OpenAI API key not found
   ```
   **Solution**: Ensure `OPENAI_API_KEY` is set in your `.env` file

2. **Import Error**
   ```
   ModuleNotFoundError: No module named 'langchain_openai'
   ```
   **Solution**: Run `pip install -r requirements.txt`

3. **Dataset Not Found**
   ```
   FileNotFoundError: [Errno 2] No such file or directory: 'datasets/SVAMP/test.json'
   ```
   **Solution**: Ensure dataset files are in the correct directory structure

4. **Code Execution Error**
   ```
   NameError: name 'some_function' is not defined
   ```
   **Solution**: Check that only predefined functions are used in generated code

5. **LangSmith Connection Issues**
   ```
   Warning: LangSmith tracing disabled
   ```
   **Solution**: Verify `LANGCHAIN_API_KEY` and project settings in `.env`

### Debug Mode

Enable debug mode for detailed logging:

```bash
# In .env file
DEBUG_MODE=true
LOG_LEVEL=DEBUG
```

### Testing Configuration

```bash
# Test with demo (no API key needed)
python demo_fpp.py

# Test configuration
python -c "from mint.config import load_config; print('Config loaded successfully')"

# Test OpenAI connection
python -c "from FPP import FunctionPrototypePrompting; from mint.config import load_config; fpp = FunctionPrototypePrompting(load_config()); print('Connection successful')"
```

## 🔬 How FPP Works

1. **Function Prototype Definition**: Predefined mathematical functions with clear signatures
2. **Prompt Construction**: Combines function prototypes with problem context
3. **Code Generation**: LLM generates Python code using only predefined functions
4. **Safe Execution**: Generated code runs in controlled environment
5. **Result Extraction**: Numerical answer extracted from execution result

### Example Workflow

```
Input: "There are 15 apples. Tom eats 3. How many are left?"

Generated Code:
total_apples = 15
eaten_apples = 3  
result = sub(total_apples, eaten_apples)

Output: 12
```

## 📈 Performance

- **SVAMP Dataset**: ~67% accuracy in demo mode
- **Code Safety**: 100% safe execution with predefined functions
- **Speed**: Fast execution with minimal overhead
- **Reliability**: Consistent results across multiple runs

## 🤝 Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt

# Run tests
python demo_fpp.py

# Check code style
python -m py_compile FPP.py
```

## 📄 License

This project is licensed under the MIT License - see the LICENSE file for details.

## 🙏 Acknowledgments

- OpenAI for GPT models
- LangChain for LLM integration framework
- SVAMP, GSM8K, FinQA, TabMWP, and TAT-QA dataset creators
- Mathematical reasoning research community

## 📞 Support

For questions, issues, or contributions:

- Open an issue on GitHub
- Check the troubleshooting section above
- Review the configuration guide

---

**Happy Mathematical Problem Solving! 🧮✨** 
